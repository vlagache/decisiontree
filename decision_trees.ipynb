{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-69204eb95b45>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-69204eb95b45>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Necessite d'installer graphviz :\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Necessite d'installer graphviz : \n",
    " - pip install graphviz\n",
    " - conda install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       ".output {\n",
       "    display: flex;\n",
       "    align-items: center;\n",
       "    text-align: center;\n",
       "}\n",
       "\n",
       ".output_text pre {\n",
       "  white-space: pre;\n",
       "  font-size: 20px;\n",
       "  text-align: center;\n",
       "  line-height: 150%;\n",
       "}\n",
       "\n",
       ".rise-enabled .output_text pre {\n",
       "  font-size: 35px;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"\"\"\n",
    "<style>\n",
    ".output {\n",
    "    display: flex;\n",
    "    align-items: center;\n",
    "    text-align: center;\n",
    "}\n",
    "\n",
    ".output_text pre {\n",
    "  white-space: pre;\n",
    "  font-size: 20px;\n",
    "  text-align: center;\n",
    "  line-height: 150%;\n",
    "}\n",
    "\n",
    ".rise-enabled .output_text pre {\n",
    "  font-size: 35px;\n",
    "}\n",
    "\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Arbres de décisions\n",
    "![iris_tree](tree-307232_640.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3b28ce07a9ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_iris\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mos\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msystem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from os import system\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "iris=load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "X = iris.data[:, 2:] # les deux dernieres valeurs de chaque ligne ( longueur et largueur du pétale )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.1, 0.1],\n",
       "       [1.2, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.3, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.7, 0.3],\n",
       "       [1.5, 0.3],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1. , 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [1.9, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.9, 1.5],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.5],\n",
       "       [4.5, 1.3],\n",
       "       [4.7, 1.6],\n",
       "       [3.3, 1. ],\n",
       "       [4.6, 1.3],\n",
       "       [3.9, 1.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.2, 1.5],\n",
       "       [4. , 1. ],\n",
       "       [4.7, 1.4],\n",
       "       [3.6, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.1, 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [3.9, 1.1],\n",
       "       [4.8, 1.8],\n",
       "       [4. , 1.3],\n",
       "       [4.9, 1.5],\n",
       "       [4.7, 1.2],\n",
       "       [4.3, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.8, 1.4],\n",
       "       [5. , 1.7],\n",
       "       [4.5, 1.5],\n",
       "       [3.5, 1. ],\n",
       "       [3.8, 1.1],\n",
       "       [3.7, 1. ],\n",
       "       [3.9, 1.2],\n",
       "       [5.1, 1.6],\n",
       "       [4.5, 1.5],\n",
       "       [4.5, 1.6],\n",
       "       [4.7, 1.5],\n",
       "       [4.4, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [4.6, 1.4],\n",
       "       [4. , 1.2],\n",
       "       [3.3, 1. ],\n",
       "       [4.2, 1.3],\n",
       "       [4.2, 1.2],\n",
       "       [4.2, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [3. , 1.1],\n",
       "       [4.1, 1.3],\n",
       "       [6. , 2.5],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.1],\n",
       "       [5.6, 1.8],\n",
       "       [5.8, 2.2],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.7],\n",
       "       [6.3, 1.8],\n",
       "       [5.8, 1.8],\n",
       "       [6.1, 2.5],\n",
       "       [5.1, 2. ],\n",
       "       [5.3, 1.9],\n",
       "       [5.5, 2.1],\n",
       "       [5. , 2. ],\n",
       "       [5.1, 2.4],\n",
       "       [5.3, 2.3],\n",
       "       [5.5, 1.8],\n",
       "       [6.7, 2.2],\n",
       "       [6.9, 2.3],\n",
       "       [5. , 1.5],\n",
       "       [5.7, 2.3],\n",
       "       [4.9, 2. ],\n",
       "       [6.7, 2. ],\n",
       "       [4.9, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [6. , 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [4.9, 1.8],\n",
       "       [5.6, 2.1],\n",
       "       [5.8, 1.6],\n",
       "       [6.1, 1.9],\n",
       "       [6.4, 2. ],\n",
       "       [5.6, 2.2],\n",
       "       [5.1, 1.5],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [5.6, 2.4],\n",
       "       [5.5, 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [5.4, 2.1],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 2.3],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.3],\n",
       "       [5.7, 2.5],\n",
       "       [5.2, 2.3],\n",
       "       [5. , 1.9],\n",
       "       [5.2, 2. ],\n",
       "       [5.4, 2.3],\n",
       "       [5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=2) # profondeur 2 \n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dotfile = open('iris_tree.dot', 'w')\n",
    "export_graphviz(\n",
    "    tree,\n",
    "    out_file=dotfile,\n",
    "    feature_names=iris.feature_names[2:],\n",
    "    class_names=iris.target_names,\n",
    "    rounded=True,\n",
    "    filled=True    \n",
    ")\n",
    "dotfile.close()\n",
    "system('dot -Tpng iris_tree.dot -o iris_tree.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![iris_tree](iris_tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Explications\n",
    "\n",
    "* Noeud Racine : est ce que la longueur du pétale est inférieure à 2.45cm , OUI / NON\n",
    "* Si OUI , on arrive à un noeud Terminal sans aucune question , prédiction = setosa\n",
    "* Si NON , est ce que la largeur du pétale est inférieure à 1.75cm etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attribut Samples \n",
    "l'attribut samples d'un noeud compte le nombre d'observations d'entrainement passées par ce noeud , par exemple 100 observations sont passés par le noeud de profondeur 1 à droite ( 100 fleurs ont une longueur de pétale supérieur à 2.45cm ) \n",
    "![Samples](samples.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attribut Values \n",
    "l'attribut values d'un noeud indique combien d'observations d'entrainement de chaque classe sont passées par la , par exemple le noeud de profondeur 2 à droite à été atteind par 0 setosa , 1 versicolor , 45 virginica \n",
    "![Value](value.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Attribut Gini\n",
    "l'attribut gini d'un noeud mesure son impureté , un noeud est pur ( gini = 0 ) si toutes les observations d'entrainement qui y aboutissent appartiennent à la meme classe\n",
    "Exemple : \n",
    "pour le noeud de gauche de profondeur 1\n",
    "![Gini](gini2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "$1 - (\\frac{0}{54})^2 - (\\frac{49}{54})^2 - (\\frac{5}{54})^2 \\approx 0.168$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formule : $G_i = 1 - \\Sigma_{k=1}^{n}p_{i,k}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p_{i,k}$ est le pourcentage d'observations de la classse k parmis toutes les toutes les observatons d'entrainement dans le ième noeud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si un noeud est \"pur\" , c'est un noeud terminal qui ne peut plus etre partagé , la zone de droite est \"impure\" mais on a spécifié au début max_depth=2 , l'arbre de décision s'arrete donc la."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimations des probabilités de classe\n",
    "Un arbre de décision peut aussi estimer la probabilité qu'une observation appartienne à une classe donnée k , Supposons par exemple que vous ayez trouvé une fleur dont les pétales mesurent 5 cm de long et 1.5cm de large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.90740741, 0.09259259]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict_proba([[5, 1.5]]) # 5cm de longueur , 1.5cm de largueur "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "L'arbre de décision renvoie les probabilités suivantes ( correspondant au noeud de profondeur 2 à gauche )  : \n",
    "- $ (\\frac{0}{54}) =  0 \\% $ pour setosa\n",
    "- $ (\\frac{49}{54}) =  90,7 \\% $ pour versicolor\n",
    "- $ (\\frac{5}{54}) =  9,3 \\% $ pour virginica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on demande à l'arbre de décision de prédire une classe il prédira donc Iris Versicolor ( classe 1 )  puisque c'est la classe avec la plus forte probabilité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['setosa', 'versicolor', 'virginica'], dtype='<U10')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.predict([[5, 1.5]]) # 5cm de longueur , 1.5cm de largueur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Algorithme d'entrainement CART ( Classification and Regression Tree ) \n",
    "\n",
    "- Scikit-Learn utilise l'algorithme CART pour entrainer les arbres de décisions \n",
    "\n",
    "Fonctionnement : \n",
    "- L'algorithme sépare d'abord le jeu d'entrainement en deux sous-ensembles en utilisant une seule caractéristique $k$ et un seuil $t_k$ ( ex : longueur de pétale <= 2.45cm ) \n",
    "- Cette paire $(k,t_k)$ est choisie en fonction de la paire qui produit les sous-ensembles les plus purs ( pondérés par leur taille )\n",
    "- La fonction de cout que l'algorithme essaie de mnimiser est la suivante :\n",
    "\n",
    "$J(k,t_k) = \\frac{Mgauche}{m} * Ggauche + \\frac{Mdroite}{m} * Gdroite $\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "$J(k,t_k) = \\frac{Mgauche}{m} * Ggauche + \\frac{Mdroite}{m} * Gdroite $\n",
    "\n",
    "avec : \n",
    "- $ Ggauche / droite $ mesure l'impureté de sous ensemble de gauche/ de droite \n",
    "- $ Mgauche / droite $ est le nombre d'observation du sous ensemble de gauche / de droite\n",
    "\n",
    "- Une fois le jeu d'entrainement partagé en deux , l'algorithme CART applique la meme logique aux sous-ensembles afin de les partager et ainsi de suite récursivement. La récursion ne s'interrompt que lorsque la profondeur maximale ( max_depth ) est atteinte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "hyperparamètres de DecisionTreeClassifier ( sklearn ) : \n",
    "\n",
    "- __max_depth__ : controle de la profondeur de l'arbre , la valeur par défault = \" None \" signifie qu'il n'y pas de limites , en réduisant max_depth on réduit le risque de surajustement\n",
    "- __min_samples_split__ : nombres minimum d'observations que doit comporter un noeud avant qu'il puisse etre divisé\n",
    "- __min_samples_leaf__ : nombres minimums d'observation qu'un noeud terminal doit avoir\n",
    "- __min_weight_fraction_leaf__ : identique à min_samples_leaf mais exprimé sous forme d'une fraction du nombre total d'observations pondérées\n",
    "- __max_leaf_nodes__ : nombre maximum de noeuds terminaux\n",
    "- __max_features__ : nombres maximum de caractéristiques évaluées à chaque noeud en vue de sa division\n",
    "                       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "                                       \n",
    "- __criterion__ : gini ou entropy , par défaut gini , mesure de l'impureté d'un noeud \n",
    "- __splitter__ : best ou random , par defaut best , la strategie utilisé pour choisir le split à chaque noeud , best pour choisir le meilleur split , ou random pour choisir le meilleur split random\n",
    "- __random_state__ : définition de la seed\n",
    "- __max_impurity_decrease__ : float par défault 0.0 , le noeud sera fractionné si le fractionnement induit une diminution de l'impureté supérieure ou égale à cette valeur\n",
    "- __min_impurity_split__ :  Seuil pour l'arret de croissance de l'arbre , un noeud se divise si son impureté est supérieure au seuil , sinon c'est un noeud terminal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "### Instabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "Les arbres de décison sont trés sensibles à de petites variations des données d'entrainement , les forets aléatoires peuvent limiter cette instabilité en effectuant une moyenne des prédictions sur de nombreux arbres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## avantages\n",
    "* Modèle white box : Ils sont simples à comprendre et à visualiser.\n",
    "* Ils nécessitent peu de préparation des données (normalisation, etc.).\n",
    "* Le coût d’utilisation des arbres est logarithmique.\n",
    "* Ils sont capables d’utiliser des données catégorielles et numériques.\n",
    "* Ils sont capables de traiter des problèmes multi-classe.\n",
    "![Avantages](avantages.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Désavantages\n",
    "\n",
    "* Overfitting Les arbres de décision peuvent créer des arbres trop complexes qui ne généralisent pas bien les données\n",
    "* Les arbres de décision peuvent être instables car de petites variations dans les données peuvent entraîner la génération d'un arbre complètement différent. C'est ce qu'on appelle la variance, qui doit être réduite par des méthodes telles que le bagging et le boosting.\n",
    "* L’apprentissage par arbre de décision crée des arbres biaisés si certaines classes dominent. Il est donc recommandé d'équilibrer l'ensemble des données avant de l'adapter à l'arbre de décision \n",
    "![Desavantages](desavantages.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![Questions](questions.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sources : \n",
    "- Machine Learning avec Scikit-Learn de Aurélien Géron\n",
    "\n",
    "- [Wikistat : Arbres binaires de décision](https://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-m-app-cart.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
